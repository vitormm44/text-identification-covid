{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this section if you want to retrain the model in your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss, Sigmoid\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, \\\n",
    "    accuracy_score, auc, average_precision_score\n",
    "from transformers import *\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import transformers\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting seeds\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '2021'\n",
    "np.random.seed(2021)\n",
    "torch.manual_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important parameters that will be used\n",
    "\n",
    "n_splits = 5 #number of folds used in cross validation\n",
    "epochs = 50 #number of training epochs\n",
    "lr = 2e-5 #learning rate\n",
    "max_length = 120 #number of tokens per data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General configs for GPU usage and reference to directories\n",
    "\n",
    "try:\n",
    "    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if device == 'cuda':\n",
    "    torch.cuda.get_device_name(0)\n",
    "\n",
    "\n",
    "def create_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(directory_path)\n",
    "        except:\n",
    "            # in case another machine created the path meanwhile !:(\n",
    "            return None\n",
    "        return None\n",
    "\n",
    "\n",
    "result_dir = './' #insert here your diretory for results\n",
    "create_directory(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './' #insert here the path of your data\n",
    "data = pd.read_csv(data_path, sep=',') #load your data\n",
    "\n",
    "#Here are defined the trained symptons\n",
    "sintomas = ['calafrio', 'congestão nasal', 'coriza', 'diarreia', 'dor de cabeça',\n",
    "       'dor muscular', 'dor de garganta', 'febre', 'perda de olfato', 'perda de paladar', 'sonolência', 'tosse',\n",
    "       'enjoo', 'cansaço'] \n",
    "\n",
    "sintomas_ingles = ['chill', 'nasal congestion', 'runny nose', 'diarrhea', 'headache',\n",
    "       'muscle pain', 'sore throat', 'fever', 'loss of smell', 'loss of taste', 'drowsiness', 'cough',\n",
    "       'sickness', 'tiredness']\n",
    "\n",
    "\n",
    "data2 = data[sintomas] #selecting the columns with the labels\n",
    "\n",
    "col_list = []\n",
    "for i in range(len(data2)):\n",
    "  list_linha = []\n",
    "  for j in range(len(data2.columns)):\n",
    "    if data2.iloc[i,j] >= 2:\n",
    "      list_linha.append(1)\n",
    "    else:\n",
    "      list_linha.append(data2.iloc[i,j])\n",
    "\n",
    "  col_list.append(list_linha)\n",
    "\n",
    "data2['one_hot'] = col_list\n",
    "\n",
    "\n",
    "texts = list(data['text'].values)\n",
    "labels = list(data2['one_hot'].values)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will pre-process the data to remove links, \"RT\", emojis, special characters and Twitter's usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = re.compile(r'http.*? |http.* ?')\n",
    "username = re.compile(r'@.*? |@.* ?')\n",
    "rt = re.compile(r'rt |RT |rT |Rt ')\n",
    "www = re.compile(r'www.*? |www.* ?')\n",
    "com = re.compile(r'.*?\\.com.*? |.*?\\.com.* ?')\n",
    "br = re.compile(r'.*?\\.br.*? |.*?\\.br.* ?')\n",
    "hashtag = re.compile(r'#.*? |#.* ?')\n",
    "emojis = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "        u\"\\U00002500-\\U00002BEF\"  \n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\" \n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "\n",
    "\n",
    "def remover(textos, regex):\n",
    "    if type(textos) == str:\n",
    "        return regex.sub('', textos)\n",
    "    else:\n",
    "        return [regex.sub('', texto) for texto in textos]\n",
    "\n",
    "\n",
    "texts = remover(texts, username)\n",
    "texts = remover(texts, http)\n",
    "texts = remover(texts, rt)\n",
    "texts = remover(texts, www)\n",
    "texts = remover(texts, com)\n",
    "texts = remover(texts, br)\n",
    "texts = remover(texts, hashtag)\n",
    "texts = remover(texts, emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the tokenizer, split and tokenize your data\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)  # tokenizer\n",
    "\n",
    "encodings = tokenizer.batch_encode_plus(texts, max_length=max_length,\n",
    "                                        pad_to_max_length=True)  \n",
    "\n",
    "print('tokenizer outputs: ', encodings.keys())\n",
    "\n",
    "\n",
    "input_ids = encodings['input_ids']  # tokenized and encoded sentences\n",
    "token_type_ids = encodings['token_type_ids']  # token type ids\n",
    "attention_masks = encodings['attention_mask']  # attention masks\n",
    "\n",
    "input_ids, test_input_ids, labels, test_labels = train_test_split(input_ids, labels, train_size=0.8,\n",
    "                                                                   random_state=10)\n",
    "token_type_ids, test_token_type_ids = train_test_split(token_type_ids, train_size=0.8, random_state=10)\n",
    "attention_masks, test_attention_masks = train_test_split(attention_masks, train_size=0.8, random_state=10)\n",
    "\n",
    "input_ids = np.array(input_ids)\n",
    "token_type_ids = np.array(token_type_ids)\n",
    "attention_masks = np.array(attention_masks)\n",
    "labels = np.array(labels)\n",
    "\n",
    "test_input_ids = np.array(test_input_ids)\n",
    "test_token_type_ids = np.array(test_token_type_ids)\n",
    "test_attention_masks = np.array(test_attention_masks)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = [[] for i in range(n_splits)]\n",
    "train_loss_set_epoch = [[] for i in range(n_splits)]\n",
    "\n",
    "val_loss_set = [[] for i in range(n_splits)]\n",
    "val_loss_set_epoch = [[] for i in range(n_splits)]\n",
    "\n",
    "train_f1_accuracy_set = [[] for i in range(n_splits)]\n",
    "train_flat_accuracy_set = [[] for i in range(n_splits)]\n",
    "\n",
    "val_f1_accuracy_set = [[] for i in range(n_splits)]\n",
    "val_flat_accuracy_set = [[] for i in range(n_splits)]\n",
    "\n",
    "pred_labels_split = [[] for i in range(n_splits)]\n",
    "true_labels_split = [[] for i in range(n_splits)]\n",
    "\n",
    "np_pred_bools_split = [[] for i in range(n_splits)]\n",
    "np_true_bools_split = [[] for i in range(n_splits)]\n",
    "\n",
    "models = [[] for i in range(n_splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckp(state):\n",
    "    f_path = result_dir + modelname + f'_{str(j)}_best_weights.pt'\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "\n",
    "#Creates the cross validation framework\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=2021)\n",
    "kfold.get_n_splits(input_ids)\n",
    "\n",
    "num_labels = len(labels[0])\n",
    "n_classes = len(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "j = 0\n",
    "\n",
    "for train_index, validation_index in kfold.split(input_ids, labels):\n",
    "    print()\n",
    "    print('--------------------------------------------------------')\n",
    "    print()\n",
    "    print(f'Current Fold: {j + 1}/{n_splits}')\n",
    "\n",
    "    valid_loss_min = 1000\n",
    "    \n",
    "    train_inputs, validation_inputs = input_ids[train_index], input_ids[validation_index]\n",
    "    train_labels, validation_labels = labels[train_index], labels[validation_index]\n",
    "    train_token_types, validation_token_types = token_type_ids[train_index], token_type_ids[validation_index]\n",
    "    train_masks, validation_masks = attention_masks[train_index], attention_masks[validation_index]\n",
    "\n",
    "\n",
    "    # Convert all of our data into torch tensors, the required datatype for our model\n",
    "    train_inputs = torch.tensor(train_inputs)\n",
    "    train_labels = torch.tensor(train_labels)\n",
    "    train_masks = torch.tensor(train_masks)\n",
    "    train_token_types = torch.tensor(train_token_types)\n",
    "    validation_inputs = torch.tensor(validation_inputs)\n",
    "    validation_labels = torch.tensor(validation_labels)\n",
    "    validation_masks = torch.tensor(validation_masks)\n",
    "    validation_token_types = torch.tensor(validation_token_types)\n",
    "\n",
    "    # Select a batch size for training.issues.\n",
    "    batch_size = 32\n",
    "\n",
    "\n",
    "    train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n",
    "    validation_sampler = SequentialSampler(validation_data)\n",
    "    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "    #carrega a BERTimbau com os nossos pesos treinados\n",
    "    model = transformers.BertForSequenceClassification.from_pretrained(\"neuralmind/bert-base-portuguese-cased\", num_labels=num_labels)\n",
    "    \n",
    "\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(result_dir + modelname + f'_0_best_weights.pt')['state_dict']) #Load our trained weights\n",
    "\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "\n",
    "    optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=lr, correct_bias=True)\n",
    "    optimizer.load_state_dict(torch.load(result_dir + modelname + f'_0_best_weights.pt')['optimizer']) #Load our trained weights\n",
    "\n",
    "    for _ in trange(epochs, desc=\"Epoch\"):\n",
    "        # Set our model to training mode\n",
    "        model.train()\n",
    "\n",
    "        tr_loss = 0  \n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "        val_loss = 0\n",
    "        nb_val_examples, nb_val_steps = 0, 0\n",
    "\n",
    "        # Train the data for one epoch\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            logits = outputs[0]\n",
    "            loss_func = BCEWithLogitsLoss()\n",
    "            loss = loss_func(logits.view(-1, num_labels).to(device), b_labels.type_as(logits).view(-1, num_labels).to(\n",
    "                device))\n",
    "            train_loss_set[j].append(loss.item())\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += b_input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "\n",
    "        print(\"Train loss: {}\".format(tr_loss / nb_tr_steps))\n",
    "\n",
    "        train_loss_set_epoch[j].append(tr_loss / nb_tr_steps)\n",
    "\n",
    "        # Accuracy of the train\n",
    "        model.eval()\n",
    "\n",
    "        logit_preds, true_labels, pred_labels = [], [], []\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "            with torch.no_grad():\n",
    "                # Forward pass\n",
    "                outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "                b_logit_pred = outs[0]\n",
    "                pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "                pred_label = pred_label.to('cpu').numpy()\n",
    "                b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            logit_preds.append(b_logit_pred)\n",
    "            true_labels.append(b_labels)\n",
    "            pred_labels.append(pred_label)\n",
    "\n",
    "        pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "        true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "        # Calculate Accuracy\n",
    "        threshold = 0.50\n",
    "        pred_bools = [pl > threshold for pl in pred_labels]\n",
    "        true_bools = [tl == 1 for tl in true_labels]\n",
    "\n",
    "        np_true_bools = np.array(true_bools)\n",
    "        np_pred_bools = np.array(pred_bools)\n",
    "\n",
    "        train_f1_accuracy = f1_score(true_bools, pred_bools, average='micro') * 100\n",
    "        train_flat_accuracy = accuracy_score(true_bools, pred_bools) * 100\n",
    "\n",
    "        train_f1_accuracy_set[j].append(train_f1_accuracy)\n",
    "        train_flat_accuracy_set[j].append(train_flat_accuracy)\n",
    "\n",
    "        # print('F1 Train Accuracy: ', train_f1_accuracy)\n",
    "        print('Train Accuracy: ', train_flat_accuracy)\n",
    "\n",
    "\n",
    "        # Validation\n",
    "\n",
    "        # Put model in evaluation mode to evaluate loss on the validation set\n",
    "        model.eval()\n",
    "\n",
    "        logit_preds, true_labels, pred_labels, tokenized_texts = [], [], [], []\n",
    "\n",
    "        for i, batch in enumerate(validation_dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "            with torch.no_grad():\n",
    "                # Forward pass\n",
    "                outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "                b_logit_pred = outs[0]\n",
    "                loss_func = BCEWithLogitsLoss()\n",
    "                loss = loss_func(b_logit_pred.view(-1, num_labels), b_labels.type_as(logits).view(-1,\n",
    "                                                                                                  num_labels))  # convert labels to float for calculation\n",
    "                val_loss_set[j].append(loss.item())\n",
    "\n",
    "                pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "                pred_label = pred_label.to('cpu').numpy()\n",
    "                b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            tokenized_texts.append(b_input_ids)\n",
    "            logit_preds.append(b_logit_pred)\n",
    "            true_labels.append(b_labels)\n",
    "            pred_labels.append(pred_label)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            nb_val_examples += b_input_ids.size(0)\n",
    "            nb_val_steps += 1\n",
    "        print(\"Validation loss: {}\".format(val_loss / nb_tr_steps))\n",
    "\n",
    "        val_loss_set_epoch[j].append(val_loss / nb_val_steps)\n",
    "\n",
    "        # create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': _ + 1,\n",
    "            'valid_loss_min': val_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "\n",
    "        if (val_loss / nb_val_steps) <= valid_loss_min:\n",
    "            save_ckp(checkpoint)\n",
    "            valid_loss_min = val_loss / nb_val_steps\n",
    "\n",
    "        pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "        true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "        pred_labels_split[j].append(pred_labels)\n",
    "        true_labels_split[j].append(true_labels)\n",
    "\n",
    "        # Calculate Accuracy\n",
    "        threshold = 0.50\n",
    "        pred_bools = [pl > threshold for pl in pred_labels]\n",
    "        true_bools = [tl == 1 for tl in true_labels]\n",
    "\n",
    "        np_true_bools = np.array(true_bools)\n",
    "        np_pred_bools = np.array(pred_bools)\n",
    "\n",
    "        np_true_bools_split[j].append(np_true_bools)\n",
    "        np_pred_bools_split[j].append(np_pred_bools)\n",
    "\n",
    "        val_f1_accuracy = f1_score(true_bools, pred_bools, average='micro') * 100\n",
    "        val_flat_accuracy = accuracy_score(true_bools, pred_bools) * 100\n",
    "\n",
    "        val_f1_accuracy_set[j].append(val_f1_accuracy)\n",
    "        val_flat_accuracy_set[j].append(val_flat_accuracy)\n",
    "\n",
    "        print('Validation Accuracy: ', val_flat_accuracy)\n",
    "\n",
    "    models[j] = model\n",
    "    j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss evolution\n",
    "\n",
    "x = np.linspace(1, epochs, epochs)\n",
    "\n",
    "val_median = np.percentile(np.vstack(val_loss_set_epoch), 50.0,\n",
    "                           axis=0)  # mediana é menos sensível a outliers que a média\n",
    "best_epoch = val_median.argmin()\n",
    "print(f'Best Epoch: {best_epoch}')\n",
    "\n",
    "values_folds = []\n",
    "for i in range(n_splits):\n",
    "    values_folds.append(val_loss_set_epoch[i][best_epoch])\n",
    "\n",
    "best_fold = np.array(values_folds).argmin()\n",
    "print(f'Best Fold: {best_fold}')\n",
    "\n",
    "train_median = np.percentile(np.vstack(train_loss_set_epoch), 50.0,\n",
    "                       axis=0)  \n",
    "train_lowlim = np.percentile(np.vstack(train_loss_set_epoch), 15.87, axis=0)\n",
    "train_highlim = np.percentile(np.vstack(train_loss_set_epoch), 84.13, axis=0)\n",
    "train_interval = (train_highlim - train_lowlim)\n",
    "train_frac_err = train_interval / train_median\n",
    "train_half_interval = train_interval / 2.0\n",
    "\n",
    "plt.title('Loss using Median and Percentiles', fontsize=15)\n",
    "plt.plot(x, train_median, label=r'Train Loss', color='C0')\n",
    "plt.fill_between(x, train_lowlim, train_highlim, color='C0', alpha=0.4)\n",
    "\n",
    "\n",
    "val_median = np.percentile(np.vstack(val_loss_set_epoch), 50.0, axis=0)  \n",
    "val_lowlim = np.percentile(np.vstack(val_loss_set_epoch), 15.87, axis=0)\n",
    "val_highlim = np.percentile(np.vstack(val_loss_set_epoch), 84.13, axis=0)\n",
    "val_interval = (val_highlim - val_lowlim)\n",
    "val_frac_err = val_interval / val_median\n",
    "val_half_interval = val_interval / 2.0\n",
    "\n",
    "plt.plot(x, val_median, label=r'Val Loss', color='C1')\n",
    "plt.fill_between(x, val_lowlim, val_highlim, color='C1', alpha=0.4)\n",
    "\n",
    "plt.xlabel(r'Epochs', fontsize=12)\n",
    "plt.ylabel(r'Loss', fontsize=12)\n",
    "plt.xticks(np.arange(0, epochs + 1, 10))\n",
    "plt.xlim(1, epochs)\n",
    "# plt.ylim(0)\n",
    "plt.legend([f'Train: {train_median[best_epoch].round(5)} +/- {train_half_interval[best_epoch].round(5)}',\n",
    "            f'Validation: {val_median[best_epoch].round(5)} +/- {val_half_interval[best_epoch].round(5)}'],\n",
    "           fontsize=12)\n",
    "\n",
    "plt.annotate(f'Best epoch: {best_epoch}',\n",
    "             xy=(1, 0.03),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Best fold's Train loss: {np.float64(val_loss_set_epoch[best_fold][best_epoch]).round(5)}\")\n",
    "print(f\"Best fold's Validation loss: {np.float64(train_loss_set_epoch[best_fold][best_epoch]).round(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy evolutions\n",
    "\n",
    "train_median = np.percentile(np.vstack(train_flat_accuracy_set), 50.0,\n",
    "                       axis=0)  \n",
    "train_lowlim = np.percentile(np.vstack(train_flat_accuracy_set), 15.87, axis=0)\n",
    "train_highlim = np.percentile(np.vstack(train_flat_accuracy_set), 84.13, axis=0)\n",
    "train_interval = (train_highlim - train_lowlim)\n",
    "train_frac_err = train_interval / train_median  \n",
    "train_half_interval = train_interval / 2.0\n",
    "\n",
    "plt.title('Validation and Train Accuracys', fontsize=15)\n",
    "plt.plot(x, train_median, label=r'Train Flat Acc', color='C0')\n",
    "plt.fill_between(x, train_lowlim, train_highlim, color='C0', alpha=0.4)\n",
    "\n",
    "print(f'Train Acc: {train_median[best_epoch].round(10)} +/- {train_half_interval[best_epoch].round(10)}')\n",
    "\n",
    "val_median = np.percentile(np.vstack(val_flat_accuracy_set), 50.0,\n",
    "                       axis=0)  \n",
    "val_lowlim = np.percentile(np.vstack(val_flat_accuracy_set), 15.87, axis=0)\n",
    "val_highlim = np.percentile(np.vstack(val_flat_accuracy_set), 84.13, axis=0)\n",
    "val_interval = (val_highlim - val_lowlim)\n",
    "val_frac_err = val_interval / val_median\n",
    "val_half_interval = val_interval / 2.0\n",
    "\n",
    "plt.plot(x, val_median, label=r'Val Flat Acc', color='C1')\n",
    "plt.fill_between(x, val_lowlim, val_highlim, color='C1', alpha=0.4)\n",
    "\n",
    "plt.xlabel(r'Epochs')\n",
    "plt.ylabel(r'Accuracy')\n",
    "plt.xlim(1, epochs)\n",
    "\n",
    "plt.legend([f'Train: {train_median[best_epoch].round(2)} +/- {train_half_interval[best_epoch].round(2)}',\n",
    "            f'Validation: {val_median[best_epoch].round(2)} +/- {val_half_interval[best_epoch].round(2)}'],\n",
    "           fontsize=12)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Validation Acc: {val_median[best_epoch].round(5)} +/- {val_half_interval[best_epoch].round(5)}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you fine tuned the model using the last section, don't run the next cell.\n",
    "\n",
    "If you want to just test the model in your data, without fine tuning, load your data and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [[] for i in range(n_splits)]\n",
    "\n",
    "for j in range(n_splits):\n",
    "    model = transformers.BertForSequenceClassification.from_pretrained(\"neuralmind/bert-base-portuguese-cased\", num_labels=14)\n",
    "\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(result_dir + modelname + f'_{j}_best_weights.pt')['state_dict'])\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.0}\n",
    "        ]\n",
    "\n",
    "    optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=lr, correct_bias=True)\n",
    "    optimizer.load_state_dict(torch.load(result_dir + modelname + f'_{j}_best_weights.pt')['optimizer'])\n",
    "    \n",
    "    models[j] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From now on, we will only use the test dataset\n",
    "\n",
    "test_pred_labels_split = [[] for i in range(n_splits)]\n",
    "test_true_labels_split = [[] for i in range(n_splits)]\n",
    "\n",
    "test_np_true_bools_split = [[] for i in range(n_splits)]\n",
    "test_np_pred_bools_split = [[] for i in range(n_splits)]\n",
    "\n",
    "test_input_ids = torch.LongTensor(test_input_ids)\n",
    "test_attention_masks = torch.Tensor(test_attention_masks)\n",
    "test_labels = torch.Tensor(test_labels)\n",
    "test_token_type_ids = torch.Tensor(test_token_type_ids)\n",
    "\n",
    "j=0\n",
    "for model in models:\n",
    "        test_data = TensorDataset(test_input_ids, test_attention_masks, test_labels, test_token_type_ids)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        logit_preds, true_labels, pred_labels = [], [], []\n",
    "\n",
    "        # Predict\n",
    "        for i, batch in enumerate(test_dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "            with torch.no_grad():\n",
    "                # Forward pass\n",
    "                outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "                b_logit_pred = outs[0]\n",
    "                pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "                pred_label = pred_label.to('cpu').numpy()\n",
    "                b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            logit_preds.append(b_logit_pred)\n",
    "            true_labels.append(b_labels)\n",
    "            pred_labels.append(pred_label)\n",
    "\n",
    "        pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "        true_labels = [item for sublist in true_labels for item in sublist]\n",
    "        \n",
    "        test_pred_labels_split[j].append(pred_labels)\n",
    "        test_true_labels_split[j].append(true_labels)\n",
    "        \n",
    "        # Calculate Accuracy\n",
    "        threshold = 0.50\n",
    "        pred_bools = [pl > threshold for pl in pred_labels]\n",
    "        true_bools = [tl == 1 for tl in true_labels]\n",
    "\n",
    "        np_true_bools = np.array(true_bools)\n",
    "        np_pred_bools = np.array(pred_bools)\n",
    "\n",
    "        test_np_true_bools_split[j].append(np_true_bools)\n",
    "        test_np_pred_bools_split[j].append(np_pred_bools)\n",
    "        \n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculations for Precision-Recall Curve\n",
    "\n",
    "PRECISIONs = []\n",
    "RECALLs = []\n",
    "\n",
    "for k in range(n_classes):\n",
    "    PRECISIONs.append(np.array(precision)[:, k])\n",
    "    RECALLs.append(np.array(recall)[:, k])\n",
    "\n",
    "PRECISIONs = np.array(PRECISIONs)\n",
    "RECALLs = np.array(RECALLs)\n",
    "\n",
    "PREDs = np.array(test_np_pred_bools_split)[:, 0]\n",
    "REALs = np.array(test_np_true_bools_split)[:, 0]\n",
    "\n",
    "average_precision = [[[] for i in range(n_splits)] for i in range(n_classes)]\n",
    "for k in range(n_splits):\n",
    "    for i in range(n_classes):\n",
    "        average_precision[i][k].append(\n",
    "            average_precision_score(test_np_true_bools_split[k][0][:, i], test_np_pred_bools_split[k][0][:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for k in range(n_classes):\n",
    "    plt.plot(np.percentile(RECALLs[k], 50, axis=0), np.percentile(PRECISIONs[k], 50, axis=0),\n",
    "             label=f'{sintomas_ingles[k]}: {np.percentile(average_precision[k], 50, axis=0).round(2)}',\n",
    "             color=f'C{k}')\n",
    "    \n",
    "    #Use the next 2 lines with you want to see the errors\n",
    "    #plt.fill_between(np.percentile(RECALLs[k], 50, axis=0)[:, 0], np.percentile(PRECISIONs[k], 84.13, axis=0)[:, 0],\n",
    "    #                 np.percentile(PRECISIONs[k], 15.87, axis=0)[:, 0], color=f'C{k}', alpha=0.4)\n",
    "\n",
    "    print(r'Classe %s : %.3f +/- %.3f' % (sintomas_ingles[k], np.percentile(average_precision[k], 50, axis=0),\n",
    "                                                                 (np.percentile(average_precision[k], 84.13,\n",
    "                                                                                axis=0) - np.percentile(\n",
    "                                                                     average_precision[k], 15.87, axis=0)) / 2.))\n",
    "plt.xlabel(r'Recall')\n",
    "plt.ylabel(r'Precision')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculations for ROC Curve\n",
    "\n",
    "fpr = [[[[] for i in range(len(threshold))] for i in range(n_classes)] for i in range(n_splits)]\n",
    "tpr = [[[[] for i in range(len(threshold))] for i in range(n_classes)] for i in range(n_splits)]\n",
    "\n",
    "for k in range(n_splits):\n",
    "    for j in range(n_classes):\n",
    "        for t in range(len(threshold)):\n",
    "            try:\n",
    "                tpr[k][j][t].append(TP[k][j][t] / (TP[k][j][t] + FN[k][j][t]))\n",
    "            except:\n",
    "                tpr[k][j][t].append(1)\n",
    "            try:\n",
    "                fpr[k][j][t].append(FP[k][j][t] / (FP[k][j][t] + TN[k][j][t]))\n",
    "            except:\n",
    "                fpr[k][j][t].append(1)\n",
    "\n",
    "\n",
    "FPRs = []\n",
    "TPRs = []\n",
    "\n",
    "for k in range(n_classes):\n",
    "    FPRs.append(np.array(fpr)[:, k])\n",
    "    TPRs.append(np.array(tpr)[:, k])\n",
    "\n",
    "FPRs = np.array(FPRs)\n",
    "TPRs = np.array(TPRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for k in range(n_classes):\n",
    "    plt.plot(np.percentile(FPRs[k], 50, axis=0), np.percentile(TPRs[k], 50, axis=0),\n",
    "             label=f'{sintomas[k]}: {auc(np.percentile(FPRs[k], 50, axis=0), np.percentile(TPRs[k], 50, axis=0)).round(2)}', color=f'C{k}')\n",
    "    \n",
    "    #Use the next 2 lines with you want to see the errors\n",
    "    #plt.fill_between(np.percentile(FPRs[k], 50, axis=0)[:, 0], np.percentile(TPRs[k], 84.13, axis=0)[:, 0],\n",
    "    #                 np.percentile(TPRs[k], 15.87, axis=0)[:, 0], color=f'C{k}', alpha=0.4)\n",
    "    \n",
    "plt.xlabel(r'TPR')\n",
    "plt.ylabel(r'FPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    result_dir + f'NTv3_model{modelname}_n_classes{n_classes}_n_folds{n_splits}_epochs{epochs}_lr{lr}_maxlenght{max_length}_trainsize{train_size}' + 'roc_com_erros.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will only the best model trained. In our data it was the model 0, so the example will use this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-01f6b07bbfa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will create a LIME function for multilabel data that already preprocess our data\n",
    "\n",
    "def multi_label_explainer(input_text, labels=sintomas, num_features=None, num_samples=None, bow=True):\n",
    "    \n",
    "    http = re.compile(r'http.*? |http.* ?')\n",
    "    username = re.compile(r'@.*? |@.* ?')\n",
    "    rt = re.compile(r'rt |RT |rT |Rt ')\n",
    "    www = re.compile(r'www.*? |www.* ?')\n",
    "    com = re.compile(r'.*?\\.com.*? |.*?\\.com.* ?')\n",
    "    br = re.compile(r'.*?\\.br.*? |.*?\\.br.* ?')\n",
    "    hashtag = re.compile(r'#.*? |#.* ?')\n",
    "    emojis = re.compile(\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                        u\"\\U0001f926-\\U0001f937\"\n",
    "                        u\"\\U00010000-\\U0010ffff\"\n",
    "                        u\"\\u2640-\\u2642\" \n",
    "                        u\"\\u2600-\\u2B55\"\n",
    "                        u\"\\u200d\"\n",
    "                        u\"\\u23cf\"\n",
    "                        u\"\\u23e9\"\n",
    "                        u\"\\u231a\"\n",
    "                        u\"\\ufe0f\"  # dingbats\n",
    "                        u\"\\u3030\"\n",
    "                                      \"]+\", re.UNICODE)\n",
    "\n",
    "    def remover(textos, regex):\n",
    "        if type(textos) == str:\n",
    "            return regex.sub('', textos)\n",
    "        else:\n",
    "            return [regex.sub('', texto) for texto in textos]\n",
    "\n",
    "\n",
    "    input_text = remover(input_text, username)\n",
    "    input_text = remover(input_text, http)\n",
    "    input_text = remover(input_text, rt)\n",
    "    input_text = remover(input_text, www)\n",
    "    input_text = remover(input_text, com)\n",
    "    input_text = remover(input_text, br)\n",
    "    input_text = remover(input_text, hashtag)\n",
    "    input_text = remover(input_text, emojis)\n",
    "    \n",
    "    for label in labels:\n",
    "        class_names = ['None', label]\n",
    "\n",
    "        def make_classifier_pipeline(label=label):\n",
    "            label_index = labels.index(label)\n",
    "    \n",
    "            def lime_explainer_pipeline(texts):    \n",
    "\n",
    "                encodings = tokenizer.batch_encode_plus(texts,max_length=150,pad_to_max_length=True)\n",
    "\n",
    "                test_input_ids = encodings['input_ids'] # tokenized and encoded sentences\n",
    "                test_token_type_ids = encodings['token_type_ids'] # token type ids\n",
    "                test_attention_masks = encodings['attention_mask'] # attention masks\n",
    "\n",
    "                test_input_ids = np.array(test_input_ids)\n",
    "                test_token_type_ids = np.array(test_token_type_ids)\n",
    "                test_attention_masks = np.array(test_attention_masks)\n",
    "\n",
    "                test_input_ids = torch.tensor(test_input_ids)\n",
    "                test_token_type_ids = torch.tensor(test_token_type_ids)\n",
    "                test_attention_masks = torch.tensor(test_attention_masks)\n",
    "\n",
    "                test_input_ids = test_input_ids.to(device)\n",
    "                test_token_type_ids = test_token_type_ids.to(device)\n",
    "                test_attention_masks = test_attention_masks.to(device)\n",
    "\n",
    "                model.to(device)\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outs = model(test_input_ids, token_type_ids=None, attention_mask=test_attention_masks)\n",
    "                    b_logit_pred = outs[0]\n",
    "                    pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "                    pred_label = pred_label.to('cpu').numpy()\n",
    "\n",
    "\n",
    "                prob_true = pred_label[:, label_index]\n",
    "    \n",
    "                result = np.transpose(np.vstack(([1-prob_true, prob_true])))  \n",
    "                result  = result.reshape(-1, 2)\n",
    "                return result\n",
    "        \n",
    "            return lime_explainer_pipeline\n",
    "       \n",
    "       # make a classifier function for the required label\n",
    "        classifer_fn = make_classifier_pipeline(label=label)\n",
    "\n",
    "        if num_samples is None:\n",
    "            num_samples = int(len(input_text.split(' ')) * 2.5)\n",
    "            num_samples = 1000 if num_samples > 1000 else num_samples\n",
    "        if num_features is None:\n",
    "            num_features = int(len(input_text.split(' ')) // 20)\n",
    "            num_features = 10 if num_features > 10 else max(num_features,1)\n",
    "\n",
    "        explainer = LimeTextExplainer(class_names=class_names, kernel_width=25, bow=bow)\n",
    "        exp = explainer.explain_instance(input_text, classifer_fn, num_features=num_features, num_samples=num_samples)\n",
    "        exp.show_in_notebook(text=True, predict_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is an example of how to call the function\n",
    "\n",
    "multi_label_explainer(texts[10], num_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
